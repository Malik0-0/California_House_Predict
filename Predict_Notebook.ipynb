{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>New Unseen Data Prediction Regression</center>\n",
    "---\n",
    "\n",
    "<center>Malik Alrasyid Basori</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run locally & on the cloud\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Need for Google Cloud (or You could just upload all of them to Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import google cloud library\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up authentication using services account \n",
    "import os\n",
    "# Authenticate using service account\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"sa-development.json\"\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../vertex-ai-ml/dti-ds-31329ac0651d.json\"\n",
    "\n",
    "project_id = 'dti-ds'\n",
    "dataset_id = 'malik_dataset_034'\n",
    "table_id = 'new_entries_in_california_housing'\n",
    "region = 'us-central1'\n",
    "bucket_name = 'malik_gcs_034'\n",
    "blob_name = 'data/new_entries_in_california_housing.csv'\n",
    "\n",
    "model_name = 'California_Housing_Price.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Google Cloud Storage - skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model from Google Cloud Storage\n",
    "try : \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name) # Add bucket name\n",
    "    blob_model = bucket.blob(f'model/{model_name}')\n",
    "    blob_model.download_to_filename('California_Housing_Price.pkl')\n",
    "\n",
    "    print (\"Read model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from BQ\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# query \n",
    "query_job = client.query(f\"\"\"select * from {dataset_id}.{table_id}\"\"\")\n",
    "batch_test = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess new data\n",
    "def preprocess_new_data(new_data):\n",
    "    # Encode 'ocean_proximity'\n",
    "    new_data['ocean_proximity'] = new_data['ocean_proximity'].replace({'ISLAND': 0, 'NEAR OCEAN': 1, '<1H OCEAN': 2, 'NEAR BAY': 3, 'INLAND': 4})\n",
    "    \n",
    "    # Create new features\n",
    "    new_data['rooms_per_household'] = new_data['total_rooms'] / new_data['households']\n",
    "    new_data['bedrooms_per_room'] = new_data['total_bedrooms'] / new_data['total_rooms']\n",
    "    new_data['population_per_household'] = new_data['population'] / new_data['households']\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_y_scaler = joblib.load('inverse_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hadi\\AppData\\Local\\Temp\\ipykernel_4208\\3014033953.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  new_data['ocean_proximity'] = new_data['ocean_proximity'].replace({'ISLAND': 0, 'NEAR OCEAN': 1, '<1H OCEAN': 2, 'NEAR BAY': 3, 'INLAND': 4})\n",
      "c:\\Users\\Hadi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'inverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m y_test_pred_loaded \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(new_data)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(y_test_pred_loaded)\n\u001b[1;32m---> 29\u001b[0m y_test_pred_loaded_original \u001b[38;5;241m=\u001b[39m \u001b[43mscaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m(y_test_pred_loaded)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     31\u001b[0m y_test_pred_loaded_original\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'inverse_transform'"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load('gb_california_model.pkl')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Example new data\n",
    "new_data = pd.DataFrame({\n",
    "    'longitude': [-118.40],\n",
    "    'latitude': [34.09],\n",
    "    'total_rooms': [10000.0],\n",
    "    'total_bedrooms': [1000.0],\n",
    "    'population': [3000.0],\n",
    "    'households': [1000.0],\n",
    "    'median_income': [15.0],\n",
    "    'housing_median_age': [5.0],\n",
    "    'ocean_proximity': ['NEAR OCEAN']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Predict on the test data using the loaded model\n",
    "new_data = preprocess_new_data(new_data)\n",
    "y_test_pred_loaded = loaded_model.predict(new_data).reshape(-1, 1)\n",
    "\n",
    "scaled = scaler.fit_transform(y_test_pred_loaded)\n",
    "\n",
    "y_test_pred_loaded_original = scaled.inverse_transform(y_test_pred_loaded).flatten()\n",
    "\n",
    "y_test_pred_loaded_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-118.4</td>\n",
       "      <td>34.09</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  total_rooms  total_bedrooms  population  households  \\\n",
       "0     -118.4     34.09      10000.0          1000.0      3000.0      1000.0   \n",
       "\n",
       "   median_income  housing_median_age  ocean_proximity  rooms_per_household  \\\n",
       "0           15.0                 5.0                1                 10.0   \n",
       "\n",
       "   bedrooms_per_room  population_per_household  \n",
       "0                0.1                       3.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.47782614]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremely low value data test\n",
    "cheap_house = pd.DataFrame({\n",
    "    'longitude': [-118.40],\n",
    "    'latitude': [34.09],\n",
    "    'total_rooms': [10000.0],\n",
    "    'total_bedrooms': [1000.0],\n",
    "    'population': [3000.0],\n",
    "    'households': [1000.0],\n",
    "    'median_income': [15.0],\n",
    "    'housing_median_age': [5.0],\n",
    "    'ocean_proximity': ['ISLAND']\n",
    "})\n",
    "\n",
    "# Predict on the test data using the loaded model\n",
    "cheap_house = preprocess_new_data(cheap_house)\n",
    "y_test_pred_loaded = loaded_model.predict(cheap_house)\n",
    "y_test_pred_loaded_original = loaded_y_scaler.inverse_transform(y_test_pred_loaded.reshape(-1, 1)).flatten()\n",
    "\n",
    "y_test_pred_loaded_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_house = pd.DataFrame({\n",
    "    'longitude': [-118.40],\n",
    "    'latitude': [34.09],\n",
    "    'total_rooms': [10000.0],\n",
    "    'total_bedrooms': [1000.0],\n",
    "    'population': [3000.0],\n",
    "    'households': [1000.0],\n",
    "    'median_income': [15.0],\n",
    "    'housing_median_age': [5.0],\n",
    "    'ocean_proximity': ['INLAND']\n",
    "})\n",
    "\n",
    "\n",
    "# Predict on the test data using the loaded model\n",
    "expensive_house = preprocess_new_data(expensive_house)\n",
    "y_test_pred_loaded = loaded_model.predict(expensive_house)\n",
    "y_test_pred_loaded_original = loaded_y_scaler.inverse_transform(y_test_pred_loaded.reshape(-1, 1)).flatten()\n",
    "\n",
    "y_test_pred_loaded_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting New Data Batch\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"batch_test.csv\"\n",
    "batch_test = pd.read_csv(data_path)\n",
    "\n",
    "batch_test = preprocess_new_data(batch_test)\n",
    "y_pred = loaded_model.predict(batch_test)\n",
    "y_pred_origin = loaded_y_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "y_pred_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test['median_house_value']=y_pred_origin\n",
    "batch_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "table_id = 'batch_test_predicted2'\n",
    "\n",
    "# Construct a bigquery client object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# define the full table id\n",
    "table_full_id = f\"{client.project}.{dataset_id}.{table_id}\"\n",
    "\n",
    "batch_test.columns = ['_'.join(i.split(' ')) for i in batch_test.columns]\n",
    "\n",
    "job = client.load_table_from_dataframe(batch_test,table_full_id)\n",
    "\n",
    "job.result()\n",
    "print(f\"Loaded {job.output_rows} rows into {table_full_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loaded_model.predict(X_test.iloc[3:13])\n",
    "# y_pred_file_cloud = loaded_model.predict(auto_cloud)\n",
    "# y_pred_file_cloud[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_cloud['CLV Prediction'] = y_pred_file_cloud\n",
    "# auto_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>Thank You</center>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
